{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "YOLOv7ONNXandTRT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade setuptools pip --user\n",
    "!pip install onnx \n",
    "!pip install onnxruntime\n",
    "#!pip install --ignore-installed PyYAML\n",
    "#!pip install Pillow\n",
    "\n",
    "!pip install protobuf<4.21.3\n",
    "!pip install onnxruntime-gpu\n",
    "!pip install onnx>=1.9.0\n",
    "!pip install onnx-simplifier>=0.3.6 --user"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sSDOngglBk_O",
    "outputId": "1ab904a0-b9d0-46cd-ba26-297be83a3e0c"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQ5fNost-gZI",
    "outputId": "396d7243-b6af-4acf-e555-38a984cd69bb"
   },
   "source": [
    "import sys\n",
    "import torch\n",
    "print(f\"Python version: {sys.version}, {sys.version_info} \")\n",
    "print(f\"Pytorch version: {torch.__version__} \")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feCaRUEI-_Os",
    "outputId": "7a488cf8-f7d7-4366-ce12-442329a9266b"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!# Download YOLOv7 code\n",
    "!git clone https://github.com/WongKinYiu/yolov7\n",
    "%cd yolov7\n",
    "!ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfZALjuo-_Md",
    "outputId": "ccda5b64-a800-4c4a-bcb9-c7e899280751"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!# Download trained weights\n",
    "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWlHa1NJ-_Jw",
    "outputId": "d32d8c3e-1d32-4ec9-bc41-d3e0f9d60497"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python detect.py --weights ./yolov7-tiny.pt --conf 0.25 --img-size 640 --source inference/images/horses.jpg"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UX7u8eqj-_Hi",
    "outputId": "8fc1e981-e105-4c71-e964-bcb3a927ad8d"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "Image.open('/content/yolov7/runs/detect/exp/horses.jpg')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "wZD-nZXX-_Ez",
    "outputId": "7486afe2-bbbb-4c12-898a-7d750dd14287"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# export ONNX for ONNX inference\n",
    "%cd /content/yolov7/\n",
    "!python export.py --weights ./yolov7-tiny.pt \\\n",
    "        --grid --end2end --simplify \\\n",
    "        --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 \\\n",
    "        --img-size 640 640 --max-wh 640 # For onnxruntime, you need to specify this value as an integer, when it is 0 it means agnostic NMS, \n",
    "                     # otherwise it is non-agnostic NMS"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VaPGM88g-_CE",
    "outputId": "c0abb5d2-b0db-4f14-9eaa-8adfdca807bf"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# show ONNX model\n",
    "!ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9lzPkMxu7B8",
    "outputId": "4aeff7ba-ff05-43f0-f725-868ec5b194ba"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Inference for ONNX model\n",
    "import cv2\n",
    "cuda = True\n",
    "w = \"/content/yolov7/yolov7-tiny.onnx\"\n",
    "img = cv2.imread('/content/yolov7/inference/images/horses.jpg')"
   ],
   "metadata": {
    "id": "Ifw8pYU11Ske"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict,namedtuple\n",
    "\n",
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
    "session = ort.InferenceSession(w, providers=providers)\n",
    "\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)\n",
    "\n",
    "names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
    "         'hair drier', 'toothbrush']\n",
    "colors = {name:[random.randint(0, 255) for _ in range(3)] for i,name in enumerate(names)}\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image = img.copy()\n",
    "image, ratio, dwdh = letterbox(image, auto=False)\n",
    "image = image.transpose((2, 0, 1))\n",
    "image = np.expand_dims(image, 0)\n",
    "image = np.ascontiguousarray(image)\n",
    "\n",
    "im = image.astype(np.float32)\n",
    "im /= 255\n",
    "im.shape\n",
    "\n",
    "outname = [i.name for i in session.get_outputs()]\n",
    "outname\n",
    "\n",
    "inname = [i.name for i in session.get_inputs()]\n",
    "inname\n",
    "\n",
    "inp = {inname[0]:im}"
   ],
   "metadata": {
    "id": "ipHqto0J0kkq"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ONNX inference\n",
    "outputs = session.run(outname, inp)[0]\n",
    "outputs"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07vh3pUa1ccC",
    "outputId": "10e8169b-611d-4fd5-d3a7-aa1e7992f077"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ori_images = [img.copy()]\n",
    "\n",
    "for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
    "    image = ori_images[int(batch_id)]\n",
    "    box = np.array([x0,y0,x1,y1])\n",
    "    box -= np.array(dwdh*2)\n",
    "    box /= ratio\n",
    "    box = box.round().astype(np.int32).tolist()\n",
    "    cls_id = int(cls_id)\n",
    "    score = round(float(score),3)\n",
    "    name = names[cls_id]\n",
    "    color = colors[name]\n",
    "    name += ' '+str(score)\n",
    "    cv2.rectangle(image,box[:2],box[2:],color,2)\n",
    "    cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2)  \n",
    "\n",
    "Image.fromarray(ori_images[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "CIRXv-gT1gQv",
    "outputId": "f1669666-a246-4fb9-9570-8a688b515490"
   },
   "execution_count": 13,
   "outputs": []
  }
 ]
}
